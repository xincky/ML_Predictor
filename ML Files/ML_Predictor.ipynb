{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "\n",
        "# Ignorar advertencias para una salida más limpia\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "63lNYJIrCUWa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uctm6E2EBzcp",
        "outputId": "773810ec-d3fc-47d3-f449-62ccd57871a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Columnas utilizadas para el modelo final ---\n",
            "['age', 'sex', 'sick', 'pregnant', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'TBG measured', 'referral source']\n",
            "Forma del dataset después de la limpieza: (3772, 29)\n",
            "\n",
            "--- Conteo de clases original ---\n",
            "binaryClass\n",
            "1    3481\n",
            "0     291\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Cargar y Limpiar el Dataset ---\n",
        "# Asegúrate de que tu archivo 'hypothyroid.csv' esté en el mismo directorio\n",
        "# o proporciona la ruta completa al archivo.\n",
        "try:\n",
        "    df = pd.read_csv('hypothyroid.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'hypothyroid.csv' no encontrado. Asegúrate de que el archivo esté en la ubicación correcta.\")\n",
        "    exit()\n",
        "\n",
        "# Reemplazar '?' con el valor nulo estándar de numpy (NaN)\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Eliminar la columna 'TBG' si existe, ya que suele estar vacía\n",
        "if 'TBG' in df.columns:\n",
        "    df.drop('TBG', axis=1, inplace=True)\n",
        "\n",
        "# Convertir la clase objetivo a formato binario (Enfermo=1, Sano=0)\n",
        "df['binaryClass'] = df['binaryClass'].map({'P': 1, 'N': 0})\n",
        "\n",
        "# Identificar y convertir columnas numéricas, manejando errores\n",
        "numeric_cols_to_convert = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n",
        "for col in numeric_cols_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Convertir columnas con valores 't'/'f' a formato binario (1/0)\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':\n",
        "        # Asegurarse de que todos los valores no nulos sean 't' o 'f'\n",
        "        if df[column].dropna().isin(['t', 'f']).all():\n",
        "            df[column] = df[column].map({'t': 1, 'f': 0})\n",
        "\n",
        "\n",
        "# --- INICIO DE LA MODIFICACIÓN FINAL ---\n",
        "\n",
        "# Lista completa de columnas a eliminar (laboratorio + historial/tratamiento)\n",
        "cols_to_drop = [\n",
        "    # Resultados de laboratorio (los que ya habías quitado)\n",
        "    'TSH measured', 'TSH',\n",
        "    'T3 measured', 'T3',\n",
        "    'TT4 measured', 'TT4',\n",
        "    'T4U measured', 'T4U',\n",
        "    'FTI measured', 'FTI',\n",
        "\n",
        "    # Nuevas columnas de historial y tratamiento (la fuga sutil)\n",
        "    'on thyroxine',\n",
        "    'query on thyroxine',\n",
        "    'on antithyroid medication',\n",
        "    'thyroid surgery',\n",
        "    'I131 treatment',\n",
        "    'query hypothyroid',\n",
        "    'query hyperthyroid'\n",
        "]\n",
        "\n",
        "# Crear el DataFrame final para un modelo predictivo \"puro\"\n",
        "X_final = df.drop(['binaryClass'] + cols_to_drop, axis=1, errors='ignore')\n",
        "y_final = df['binaryClass']\n",
        "\n",
        "print(\"\\n--- Columnas utilizadas para el modelo final ---\")\n",
        "print(X_final.columns.tolist())\n",
        "\n",
        "# AHORA, VUELVE A EJECUTAR TODO TU PIPELINE CON ESTOS DATOS FINALES:\n",
        "# 1. Haz el train_test_split con X_final y y_final\n",
        "# 2. Ajusta tu preprocesador y aplica SMOTE\n",
        "# 3. Entrena tu modelo XGBoost regularizado\n",
        "# 4. Evalúa los resultados que obtengas\n",
        "\n",
        "# --- FIN DE LA MODIFICACIÓN FINAL ---\n",
        "\n",
        "\n",
        "print(\"Forma del dataset después de la limpieza:\", df.shape)\n",
        "print(\"\\n--- Conteo de clases original ---\")\n",
        "print(df['binaryClass'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "IqUnOQFhBxV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Preparación de Datos para el Modelo ---\n",
        "# Separar características (X) y variable objetivo (y)\n",
        "X = df.drop('binaryClass', axis=1)\n",
        "y = df['binaryClass']\n",
        "\n",
        "# Identificar automáticamente las características numéricas y categóricas\n",
        "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "X70yESPlB_ej"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Definir el Pipeline de Preprocesamiento ---\n",
        "# Pipeline para datos numéricos: imputar valores faltantes con la mediana y escalar\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline para datos categóricos: imputar valores faltantes con el más frecuente y codificar\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combinar ambos pipelines en un único preprocesador\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "WXzg86pHCD6C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Aplicar Preprocesamiento y Balanceo con SMOTE ---\n",
        "# Aplicar el preprocesador al conjunto de entrenamiento\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Aplicar el mismo preprocesador (ya ajustado) al conjunto de prueba\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"\\n--- Aplicando SMOTE al conjunto de entrenamiento... ---\")\n",
        "smote = SMOTE(random_state=42, k_neighbors=5)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "print(\"\\n--- Conteo de clases después de SMOTE ---\")\n",
        "print(pd.Series(y_train_resampled).value_counts())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQMp8WCcCLJh",
        "outputId": "6d02693f-4441-416f-c348-9bbbecaf4823"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Aplicando SMOTE al conjunto de entrenamiento... ---\n",
            "\n",
            "--- Conteo de clases después de SMOTE ---\n",
            "binaryClass\n",
            "1    2784\n",
            "0    2784\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Entrenar el Modelo XGBoost ---\n",
        "model_xgb = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "\n",
        "    # --- Parámetros de Regularización ---\n",
        "    max_depth=4,          # Limitar la profundidad del árbol\n",
        "    gamma=0.1,            # Hacer el modelo más conservador\n",
        "    subsample=0.8,        # Usar el 80% de los datos para cada árbol\n",
        "    colsample_bytree=0.8, # Usar el 80% de las columnas para cada árbol\n",
        "    reg_lambda=1          # Regularización L2\n",
        ")\n",
        "\n",
        "print(\"\\n--- Entrenando el modelo XGBoost con datos balanceados... ---\")\n",
        "model_xgb.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"¡Entrenamiento completado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MM6mbskEe7q",
        "outputId": "f3c5b8cc-56b9-4c74-849f-87e9d0afcdfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Entrenando el modelo XGBoost con datos balanceados... ---\n",
            "¡Entrenamiento completado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Evaluar el Rendimiento del Modelo ---\n",
        "print(\"\\n--- Evaluación del Modelo en el Conjunto de Prueba ---\")\n",
        "y_pred = model_xgb.predict(X_test_processed)\n",
        "\n",
        "print(f\"\\nPrecisión (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nMatriz de Confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Sano (N)', 'Enfermo (P)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvGEFtN9CPAa",
        "outputId": "374f0d0d-d203-494b-f6d3-0982f180dc11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluación del Modelo en el Conjunto de Prueba ---\n",
            "\n",
            "Precisión (Accuracy): 0.9974\n",
            "\n",
            "Matriz de Confusión:\n",
            "[[ 57   1]\n",
            " [  1 696]]\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Sano (N)       0.98      0.98      0.98        58\n",
            " Enfermo (P)       1.00      1.00      1.00       697\n",
            "\n",
            "    accuracy                           1.00       755\n",
            "   macro avg       0.99      0.99      0.99       755\n",
            "weighted avg       1.00      1.00      1.00       755\n",
            "\n"
          ]
        }
      ]
    }
  ]
}